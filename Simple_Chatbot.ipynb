{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOS76JB8dRyDNT7At7g3d8H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/Chatbot/blob/main/Simple_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlite3 nltk\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"candidates.db\")\n",
        "c = conn.cursor()\n",
        "\n",
        "c.execute('''CREATE TABLE IF NOT EXISTS candidates (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                name TEXT,\n",
        "                skills TEXT,\n",
        "                budget INTEGER,\n",
        "                full_time INTEGER,\n",
        "                github_username TEXT,\n",
        "                experience_at_big_tech INTEGER\n",
        "            )''')\n",
        "\n",
        "c.execute(\"INSERT INTO candidates (name, skills, budget, full_time, github_username, experience_at_big_tech) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "          (\"John Doe\", \"Python, JavaScript\", 50000, 1, \"johndoe\", 1))\n",
        "c.execute(\"INSERT INTO candidates (name, skills, budget, full_time, github_username, experience_at_big_tech) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "          (\"Jane Doe\", \"React, Node.js\", 30000, 0, \"janedoe\", 0))\n",
        "c.execute(\"INSERT INTO candidates (name, skills, budget, full_time, github_username, experience_at_big_tech) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "          (\"Bob Smith\", \"AWS, Java\", 70000, 1, \"bobsmith\", 1))\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMWoYxofbXXh",
        "outputId": "ddfadbdd-d1bf-4173-ef2d-75f1ed6598d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sqlite3 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sqlite3\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "def process_query(query):\n",
        "    # Tokenize the query\n",
        "    tokens = word_tokenize(query)\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "    # Lemmatize the tokens\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "\n",
        "    # Create a frequency distribution of the tokens\n",
        "    fdist = FreqDist(lemmatized_tokens)\n",
        "\n",
        "    # Map the tokens to their corresponding categories (skills, budget, etc.)\n",
        "    categories = defaultdict(int)\n",
        "    for token, freq in fdist.items():\n",
        "        if re.match(r'\\d+', token):\n",
        "            categories['budget'] += freq\n",
        "        elif token in ('full-time', 'part-time'):\n",
        "            categories['full_time'] += freq\n",
        "        elif token in ('python', 'react', 'aws'):\n",
        "            categories['skills'] += freq\n",
        "        elif token in ('big tech', 'google', 'facebook', 'amazon', 'microsoft'):\n",
        "            categories['experience_at_big_tech'] += freq\n",
        "        # Removed the 'else' block to avoid the 'other' category\n",
        "        # else:\n",
        "        #     categories['other'] += freq\n",
        "\n",
        "    # Return the processed categories\n",
        "    return categories\n",
        "\n",
        "def get_candidates(skills=None, budget=None, full_time=None, github_username=None, experience_at_big_tech=None):\n",
        "    # Set default values for all parameters to handle cases when they are not provided\n",
        "    query_str = \"\"\"\n",
        "                SELECT * FROM candidates\n",
        "                WHERE 1=1\n",
        "                \"\"\"\n",
        "    params = ()\n",
        "\n",
        "    if skills:\n",
        "        query_str += \" AND skills LIKE ?\" # Use a placeholder for the LIKE parameter\n",
        "        params += (f'%{skills}%',) # Pass the formatted skill string as a parameter\n",
        "    if budget:\n",
        "        query_str += \" AND budget >= ?\"\n",
        "        params += (budget,)\n",
        "    if full_time:\n",
        "        query_str += \" AND full_time = ?\"\n",
        "        params += (full_time,)\n",
        "    if github_username:\n",
        "        query_str += \" AND github_username = ?\"\n",
        "        params += (github_username,)\n",
        "    if experience_at_big_tech:\n",
        "        query_str += \" AND experience_at_big_tech = ?\"\n",
        "        params += (experience_at_big_tech,)\n",
        "\n",
        "    return query_str, params\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Connect to the SQLite database\n",
        "    conn = sqlite3.connect('candidates.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Prompt the user for the query\n",
        "    while True:\n",
        "        query = input(\"What are you looking for? \")\n",
        "        categories = process_query(query)\n",
        "\n",
        "        if not categories:\n",
        "            print(\"Sorry, I need more information to assist you.\")\n",
        "        else:\n",
        "            query_str, params = get_candidates(**categories) # This should work now as 'other' is not in categories and missing arguments are handled\n",
        "            c.execute(query_str, params)\n",
        "            candidates = c.fetchall()\n",
        "            if candidates:\n",
        "                print(\"Here are some candidates:\")\n",
        "                for candidate in candidates:\n",
        "                    print(f\"Name: {candidate[1]}, Skills: {candidate[2]}, Budget: {candidate[3]}, Full-Time: {candidate[4]}, GitHub Username: {candidate[5]}, Experience at Big Tech: {candidate[6]}\")\n",
        "            else:\n",
        "                print(\"No candidates found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e2GuNBxeAjy",
        "outputId": "d91bac7b-ebf9-4df4-c7f0-9d174b6b3236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are you looking for? candidate\n",
            "Sorry, I need more information to assist you.\n",
            "What are you looking for? Skills\n",
            "Sorry, I need more information to assist you.\n",
            "What are you looking for? Budget\n",
            "Sorry, I need more information to assist you.\n",
            "What are you looking for? Full-Time\n",
            "Here are some candidates:\n",
            "Name: John Doe, Skills: Python, JavaScript, Budget: 50000, Full-Time: 1, GitHub Username: johndoe, Experience at Big Tech: 1\n",
            "Name: Bob Smith, Skills: AWS, Java, Budget: 70000, Full-Time: 1, GitHub Username: bobsmith, Experience at Big Tech: 1\n",
            "Name: John Doe, Skills: Python, JavaScript, Budget: 50000, Full-Time: 1, GitHub Username: johndoe, Experience at Big Tech: 1\n",
            "Name: Bob Smith, Skills: AWS, Java, Budget: 70000, Full-Time: 1, GitHub Username: bobsmith, Experience at Big Tech: 1\n",
            "What are you looking for? thanks\n",
            "Sorry, I need more information to assist you.\n",
            "What are you looking for? Java\n",
            "Sorry, I need more information to assist you.\n",
            "What are you looking for? Python\n",
            "No candidates found.\n"
          ]
        }
      ]
    }
  ]
}