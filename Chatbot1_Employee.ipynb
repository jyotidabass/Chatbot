{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVnDqDPghsg20fe8H/t2Iz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/Chatbot/blob/main/Chatbot1_Employee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code imports the necessary libraries, including sqlite3, numpy, and a pre-trained FastText model from the gensim library. The FastText model is a pre-trained word embedding model that can be used for text processing and natural language tasks.**"
      ],
      "metadata": {
        "id": "9w4I8M5WJuEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Load a valid pre-trained FastText model\n",
        "# Check the available models at https://github.com/RaRe-Technologies/gensim-data\n",
        "model = api.load('fasttext-wiki-news-subwords-300')"
      ],
      "metadata": {
        "id": "lbQ8mFXTW-bg",
        "outputId": "fb8e847d-c0fd-47f3-9730-ae730aed6c71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=======================---------------------------] 46.6% 446.8/958.4MB downloaded"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code block initializes a list of candidate data, with each candidate represented as a dictionary containing various attributes, including a placeholder for an embedding. It then installs the faiss-cpu package and imports the faiss library. The code then extracts the embeddings from the candidate data into a NumPy array for further processing.**"
      ],
      "metadata": {
        "id": "eKtAYs6wKCZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example engineer data\n",
        "engineer_data = [\n",
        "    {\"name\": \"John Doe\", \"company\": \"Google\", \"skills\": [\"Python\", \"React\"], \"full_time\": True, \"budget\": 10000, \"embedding\": [0.1, 0.2, ...] }, # Replace with a placeholder embedding or a method to generate embeddings for names\n",
        "    {\"name\": \"Jane Smith\", \"company\": \"Microsoft\", \"skills\": [\"AWS\", \"SQL\"], \"full_time\": True, \"budget\": 12000, \"embedding\": [0.3, 0.4, ...] },\n",
        "    {\"name\": \"Bob Johnson\", \"company\": \"Facebook\", \"skills\": [\"Python\", \"Node.js\"], \"full_time\": False, \"budget\": 8000, \"embedding\": [0.5, 0.6, ...] },\n",
        "]\n",
        "\n",
        "!pip install faiss-cpu\n",
        "import faiss\n",
        "\n",
        "# Extract embeddings into a NumPy array\n",
        "embeddings = np.array([eng[\"embedding\"] for eng in engineer_data])"
      ],
      "metadata": {
        "id": "aXgA-6QlXBNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code defines a function, process_query, which takes a user query, embeddings, a Faiss index, a tokenizer, a pre-trained language model, and a database connection as inputs. It processes the query, generates embeddings for it, searches for nearest neighbors in the Faiss index, filters results based on scalar requirements, executes a SQL search, and yields the results. The function also prompts the user for follow-up questions and demonstrates its usage.**"
      ],
      "metadata": {
        "id": "2cYB_lUBKMI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query(query, embeddings, index, tokenizer, model, conn):\n",
        "    # Preprocess the user query\n",
        "    input_ids = tokenizer(query, return_tensors='pt').input_ids.squeeze(0)\n",
        "\n",
        "    # Generate embeddings for the query\n",
        "    with model.no_grad():\n",
        "        query_embedding = model(input_ids).last_hidden_state.mean(dim=1)\n",
        "\n",
        "    # Search for the nearest neighbors\n",
        "    D, I = index.search(query_embedding.unsqueeze(0), 20)\n",
        "\n",
        "    # Filter results based on scalar requirements\n",
        "    scalar_results = []\n",
        "    for i in I[0]:\n",
        "        if embeddings[i].dot(np.array([1, 1, 1, 0]).astype(np.float64)) >= 0:  # Full-time\n",
        "            if embeddings[i].dot(np.array([1, 1, 1, 1, 1]).astype(np.float64)) >= 0:  # 100K+\n",
        "                scalar_results.append(i)\n",
        "\n",
        "    # Execute a SQL search based on the nearest neighbors\n",
        "    with conn:\n",
        "        for idx in scalar_results:\n",
        "            cursor = conn.execute(\"SELECT * FROM engineers WHERE rowid = ?\", (idx,))\n",
        "            result = cursor.fetchone()\n",
        "            if result:\n",
        "                yield f\"{result[1]} {result[2]} at {result[3]} ({result[4]} similarity)\"\n",
        "\n",
        "    # Follow up with the user\n",
        "    print(\"Would you prefer a full-time or part-time worker?\")\n",
        "\n",
        "    # Example usage\n",
        "    query = \"I want to hire someone with experience in Python and Node.js. My budget is $10000 a month.\"\n",
        "    conn = sqlite3.connect('engineers.db')\n",
        "    index = faiss.IndexFlatL2(embeddings[0].shape[0])\n",
        "    index.add(embeddings.T)\n",
        "    response = list(process_query(query, embeddings, index, tokenizer, model, conn))\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "bTLwRDV7ZveA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}